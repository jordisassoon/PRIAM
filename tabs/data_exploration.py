import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import altair as alt
from scipy.spatial import distance
from sklearn.metrics.pairwise import rbf_kernel
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import umap
from sklearn.neighbors import KernelDensity
import plotly.express as px
import shutil

from utils.map_utils import generate_map

# ======================
# ðŸ”¹ CACHING UTILITIES
# ======================

@st.cache_data
def load_csv(file):
    """Read a CSV file safely with caching."""
    file.seek(0)
    return pd.read_csv(file, encoding="latin1")

@st.cache_data
def normalize_rows(df):
    """Normalize rows to sum to 1."""
    row_sums = df.sum(axis=1)
    return df.div(row_sums.replace(0, np.nan), axis=0).fillna(0)

@st.cache_data
def compute_mmd(X_train, X_test, gamma=1.0):
    """Compute Maximum Mean Discrepancy (MMD) between train/test."""
    XX = rbf_kernel(X_train, X_train, gamma)
    YY = rbf_kernel(X_test, X_test, gamma)
    XY = rbf_kernel(X_train, X_test, gamma)
    return np.mean(XX) + np.mean(YY) - 2 * np.mean(XY)

@st.cache_data
def compute_pca_kde(X_train, X_test, bandwidth=0.5):
    """Compute PCA + KDE density probabilities for test samples."""
    pca = PCA(n_components=10, random_state=42)
    X_train_pca = pca.fit_transform(X_train)
    X_test_pca = pca.transform(X_test)

    kde = KernelDensity(kernel="gaussian", bandwidth=bandwidth).fit(X_train_pca)
    log_probs = kde.score_samples(X_test_pca)
    probs = np.exp(log_probs)
    probs_norm = (probs - probs.min()) / (probs.max() - probs.min())
    return probs_norm

@st.cache_resource
def compute_embeddings(X_train, X_test):
    """Compute PCA, t-SNE, and UMAP embeddings for visualization."""
    combined = np.vstack([X_train, X_test])
    labels = ["Train"] * len(X_train) + ["Test"] * len(X_test)

    # PCA
    pca = PCA(n_components=2)
    pca_emb = pca.fit_transform(combined)

    # t-SNE
    tsne = TSNE(n_components=2, random_state=42, perplexity=30)
    tsne_emb = tsne.fit_transform(combined)

    # UMAP
    reducer = umap.UMAP(random_state=42)
    umap_emb = reducer.fit_transform(combined)

    return pca_emb, tsne_emb, umap_emb, labels

@st.cache_resource
def cached_generate_map(train_proxy_file, coords_file, topo):
    new_topo = topo
    """Cache the map generation process."""
    output_html = "map_output.html"
    return generate_map(train_proxy_file, coords_file, output_html=output_html, topo=new_topo)


# ======================
# ðŸ”¹ MAIN APP FUNCTION
# ======================

def show_tab(train_climate_file, train_proxy_file, test_proxy_file, coords_file, axis):
    st.header("Data Exploration: Distribution & Trainâ€“Test Comparison")

    if not train_climate_file:
        st.warning("To begin exploring data, please upload the training climate dataset.")
        return

    # === Load climate data ===
    climate_df = load_csv(train_climate_file)

    # === Climate Variables Scatter Plot ===
    st.subheader("Modern Climate Variables Scatter Plot")

    climate_options = [
        "TANN", "Temp_season", "MTWA", "MTCO", "PANN",
        "Temp_wet", "Temp_dry", "P_wet", "P_dry", "P_season",
    ]
    col1, col2 = st.columns(2)
    with col1:
        x_var = st.selectbox("X-axis climate variable", climate_options, key="x_var_only")
    with col2:
        y_var = st.selectbox(
            "Y-axis climate variable", [x for x in climate_options if x != x_var], key="y_var_only"
        )

    if x_var not in climate_df.columns or y_var not in climate_df.columns:
        st.error("Selected climate variables not found in the dataset.")
    else:
        obs_df = climate_df.copy()
        obs_df["Type"] = "Modern"
        x_min, x_max = obs_df[x_var].min(), obs_df[x_var].max()
        y_min, y_max = obs_df[y_var].min(), obs_df[y_var].max()

        scatter_chart = (
            alt.Chart(obs_df)
            .mark_circle(size=60, opacity=0.7)
            .encode(
                x=alt.X(f"{x_var}:Q", title=x_var, scale=alt.Scale(domain=(x_min, x_max))),
                y=alt.Y(f"{y_var}:Q", title=y_var, scale=alt.Scale(domain=(y_min, y_max))),
                tooltip=[
                    alt.Tooltip("Type:N"),
                    alt.Tooltip("OBSNAME:N"),
                    alt.Tooltip("Age:Q"),
                    alt.Tooltip(f"{x_var}:Q"),
                    alt.Tooltip(f"{y_var}:Q"),
                ],
            )
            .interactive()
        )
        st.altair_chart(scatter_chart, use_container_width=True)

    # === Training Proxy File ===
    if not train_proxy_file:
        st.warning("To plot taxa distributions and compare trainâ€“test distributions, please upload the training proxy dataset.")
        return

    train_df = load_csv(train_proxy_file)

    # Determine labels based on the flag
    train_labels = train_df["OBSNAME"].astype(str)

    # === Taxa Preference Plot ===
    st.subheader("Taxa Preference per Climate Target")
    selected_target = st.selectbox("Select target climate variable", climate_options)

    taxa_list = [c for c in train_df.columns if c != "OBSNAME"]
    selected_taxa = st.selectbox("Select taxa for distribution plot", taxa_list)
    bins = st.slider("Number of bins for target variable", 1, 500, 25)

    merged_df = pd.merge(train_df, climate_df, on="OBSNAME", how="inner")
    merged_df["binned_target"] = pd.cut(merged_df[selected_target], bins=bins)
    taxa_sum = merged_df.groupby("binned_target")[selected_taxa].sum()
    total_count = merged_df.groupby("binned_target")[selected_taxa].count()
    preference = (taxa_sum / total_count).reset_index()
    preference.rename(columns={selected_taxa: "preference"}, inplace=True)
    preference["bin_label"] = preference["binned_target"].apply(lambda x: f"{x.left:.2f}â€“{x.right:.2f}")

    chart = (
        alt.Chart(preference)
        .mark_bar()
        .encode(
            x=alt.X("bin_label:N", title=selected_target),
            y=alt.Y("preference:Q", title=f"{selected_taxa} Average Count"),
            tooltip=[alt.Tooltip("bin_label:N"), alt.Tooltip("preference:Q")],
        )
    )
    st.altair_chart(chart, use_container_width=True)

    # === Train vs Test Distribution Comparison ===
    if not test_proxy_file:
        st.warning("To compare your train and test proxies, please upload the test proxy dataset.")
    else:
        test_df = load_csv(test_proxy_file)
        
        if axis == "Age":
            test_labels = test_df["Age"].apply(lambda x: f"Age: {x}").astype(str)
        elif axis == "Depth":
            test_labels = test_df["Depth"].apply(lambda x: f"Depth: {x}").astype(str)
        else:
            test_labels = test_df.index.astype(str)
        
        labels = pd.concat([train_labels, test_labels], ignore_index=True)

        shared_cols = [c for c in train_df.columns if c in test_df.columns and c != "OBSNAME"]
        X_train = normalize_rows(train_df[shared_cols])
        X_test = normalize_rows(test_df[shared_cols])

        # --- Compute Metrics ---
        mmd_value = compute_mmd(X_train, X_test, gamma=1.0 / X_train.shape[1])
        st.metric("MMD (RBF Kernel)", f"{mmd_value:.5f}")

        probs_norm = compute_pca_kde(X_train, X_test)
        st.metric("Mean likelihood (PCA-KDE)", f"{np.mean(probs_norm):.3f}")

        kde_df = pd.DataFrame({"Test Sample": np.arange(len(probs_norm)), "Probability": probs_norm})
        kde_df["Sample"] = test_labels
        fig = px.bar(kde_df, x="Test Sample", y="Probability", hover_name="Sample", title="Test Sample Likelihood (PCA-KDE)")
        fig.update_layout(yaxis_title="Normalized Probability", xaxis_title="Test Sample Index")
        st.plotly_chart(fig, use_container_width=True)

        # --- Embeddings ---
        st.subheader("Low-Dimensional Embeddings (Train vs Test)")
        pca_emb, tsne_emb, umap_emb, set_labels = compute_embeddings(X_train, X_test)

        # PCA Plot
        pca_df = pd.DataFrame(pca_emb, columns=["PC1", "PC2"])
        pca_df["Sample"] = labels
        pca_df["Set"] = set_labels
        fig_pca = px.scatter(
            pca_df, x="PC1", y="PC2", color="Set", hover_name="Sample", title="PCA Projection",
            color_discrete_map={"Train": "steelblue", "Test": "red"}
        )
        st.plotly_chart(fig_pca, use_container_width=True)

        # t-SNE Plot
        tsne_df = pd.DataFrame(tsne_emb, columns=["Dim1", "Dim2"])
        tsne_df["Sample"] = labels
        tsne_df["Set"] = set_labels
        fig_tsne = px.scatter(
            tsne_df, x="Dim1", y="Dim2", color="Set", hover_name="Sample", title="t-SNE Projection",
            color_discrete_map={"Train": "steelblue", "Test": "red"}
        )
        st.plotly_chart(fig_tsne, use_container_width=True)

        # UMAP Plot
        umap_df = pd.DataFrame(umap_emb, columns=["UMAP1", "UMAP2"])
        umap_df["Sample"] = labels
        umap_df["Set"] = set_labels
        fig_umap = px.scatter(
            umap_df, x="UMAP1", y="UMAP2", color="Set", hover_name="Sample", title="UMAP Projection",
            color_discrete_map={"Train": "steelblue", "Test": "red"}
        )
        st.plotly_chart(fig_umap, use_container_width=True)

    # === Coordinates Map ===
    if not coords_file:
        st.warning("To plot your samples on a geographic map, please upload the training proxy coordinates dataset.")
        return

    st.subheader("Site Coordinates Map")
    map_path = cached_generate_map(train_proxy_file, coords_file, False)

    with open(map_path, "r", encoding="utf-8") as f:
        map_html = f.read()
    st.components.v1.html(map_html, height=800, scrolling=True)

    with open(map_path, "rb") as f:
        st.download_button("Download Map HTML", f, file_name="map_output.html", mime="text/html")
